expt: 33
notes: Features used - resnet, optical flow, openpose ( new normalized ); mult last out
save_path: /home/nrk1787/slt_phase2/models/multimodal_transformer/data/33

data:
    sl: asl
    vocab: /home/nrk1787/slt_phase2/Datasets/ASL_2/vocab/new_vocab.txt
    train: /home/nrk1787/slt_phase2/Datasets/ASL_2/ground_truth/preprocessed_csvs/new_asl_2_preprocessed_train.csv
    val: /home/nrk1787/slt_phase2/Datasets/ASL_2/ground_truth/preprocessed_csvs/new_asl_2_preprocessed_test.csv
    test: /home/nrk1787/slt_phase2/Datasets/ASL_2/ground_truth/preprocessed_csvs/new_asl_2_preprocessed_test.csv
    vid_col: Video_name
    caption_col: Caption
    features:
        f1:
            name: resnet50
            path: /home/nrk1787/slt_phase2/Datasets/ASL_2/features/new/resnet50
        f2: 
            name: optical_flow
            path: /home/nrk1787/slt_phase2/Datasets/ASL_2/features/new/optical_flow/features
        f3: 
            name: openpose
            path: /home/nrk1787/slt_phase2/Datasets/ASL_2/features/new/openpose/after_smoothing_new_normalised
    pad_index: 1

model:
    type: mult_modified
    batch_size: 8
    shuffle: True
    f1_only: True
    f2_only: True
    f3_only: True
    capture_wts: True 
    optimizer:
        lr: 1.0e-3
        betas:
            - 0.9
            - 0.998
        eps: 1.0e-8
        weight_decay: 0.001
        amsgrad: False
    scheduler:
        mode: max
        patience: 8
        factor: 0.7
        threshold_mode: abs
        verbose: False
    loss:
        smoothing: 0.0
        translation_normalization_mode: 'batch'
        translation_loss_weight: 1.0
        batch_multiplier: 1
    encoder:
        emb_dim: 512 
        attn_dropout_mem: 0
        attn_dropout_f1: 0.1
        attn_dropout_f2: 0.0
        attn_dropout_f3: 0.0
        num_layers: 3
        num_heads: 8
        attn_mask: True
        embed_dropout: 0.1
        relu_dropout: 0.1
        res_dropout: 0.1
    decoder:
        emb_dim: 1536
        scale: False
        norm_type: 'batch'
        activation_type: softsign
        num_layers: 3
        num_heads: 8
        max_out_len: 30

inference:
    ckpt: /home/nrk1787/slt_phase2/models/multimodal_transformer/data/33/ckpt/best.ckpt
    save_attn_wts_path: /home/nrk1787/slt_phase2/models/multimodal_transformer/data/33/attn_wts.pkl
misc:
    seed: 42
    use_cuda: True
    max_output_length: 30
    wandb: False



